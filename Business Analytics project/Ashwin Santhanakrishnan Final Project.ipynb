{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87028929",
   "metadata": {},
   "source": [
    "# Final Project: Loan Acceptance Prediction\n",
    "\n",
    "**Name:** Ashwin Santhanakrishnan <br>\n",
    "**Course:** Business Data Analytics\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df667b5f",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1: Load Libraries\n",
    "\n",
    "In this step, I am importing all the necessary Python libraries for data processing, machine learning model building, evaluation, and preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bd7487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a6aae4",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Load and Clean the Dataset\n",
    "\n",
    "I loaded the dataset bank.csv into a pandas DataFrame. Infinite values are replaced with NaN to clean the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d563ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('bank.csv')\n",
    "data = data.replace([np.inf, -np.inf], np.nan)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5e8f40",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Preprocessing\n",
    "\n",
    "- In this step, I prepared the dataset for machine learning by converting all categorical columns into numerical form.\n",
    "- Since machine learning models work only with numbers, I used Label Encoding to convert text-based categories into integers.\n",
    "- I wrote a loop to check each column's data type and applied encoding only to those that were of type 'object'.\n",
    "- The encoded values replaced the original values in the dataset so that the models can train properly.\n",
    "- I also stored each encoder in a dictionary in case I needed to decode or reuse them later.\n",
    "- After encoding, I printed the data types to confirm that all columns are now numeric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b16dad07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                      int64\n",
       "Age                     int64\n",
       "Experience              int64\n",
       "Income                  int64\n",
       "ZIP Code                int64\n",
       "Family                  int64\n",
       "CCAvg                 float64\n",
       "Education               int64\n",
       "Mortgage                int64\n",
       "Personal Loan           int64\n",
       "Securities Account      int64\n",
       "CD Account              int64\n",
       "Online                  int64\n",
       "CreditCard              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lencoders = {}\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        data[column] = le.fit_transform(data[column])\n",
    "        lencoders[column] = le\n",
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb87c8",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4: Partition Data into Training and Validation Sets\n",
    "\n",
    "- I partition the dataset into training (70%) and validation (30%) in step 4.\n",
    "- The training set is used to train the machine learning models.\n",
    "- The validation set is used to evaluate the performance of the models on unseen data.\n",
    "- I partitioned the dataset with the train_test_split function from sklearn.\n",
    "- I have changed random_state=1 to ensure that outcome are reproducible at any time that I run the code.\n",
    "- I have printed rows of the two sets so that I can see if the split has indeed taken place.\n",
    "- This is done to avoid overfitting and to ensure that an unbiased estimate of model performance is obtained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "712c7e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size (A_train): 3500 rows\n",
      "Validation set size (B_val): 1500 rows\n"
     ]
    }
   ],
   "source": [
    "A = data.drop('Personal Loan', axis=1)\n",
    "B = data['Personal Loan']\n",
    "A_train, A_val, B_train, B_val = train_test_split(A, B, test_size=0.3, random_state=1)\n",
    "print(f\"Training set size (A_train): {A_train.shape[0]} rows\")\n",
    "print(f\"Validation set size (B_val): {B_val.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411af5b0",
   "metadata": {},
   "source": [
    "\n",
    "## Step 5: Build Models\n",
    "\n",
    "I choose this three classification models:\n",
    "- Naive Bayes Classifier\n",
    "- Decision Tree Classifier\n",
    "- Random Forest Classifier \n",
    "\n",
    "And Each model is trained using the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ea721cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "modelnb = GaussianNB()\n",
    "modelnb.fit(A_train, B_train)\n",
    "prednb = modelnb.predict(A_val)\n",
    "\n",
    "# Decision Tree\n",
    "modeltree = DecisionTreeClassifier(random_state=1)\n",
    "modeltree.fit(A_train, B_train)\n",
    "preddt = modeltree.predict(A_val)\n",
    "\n",
    "# Random Forest\n",
    "modelforest = RandomForestClassifier(random_state=1)\n",
    "modelforest.fit(A_train, B_train)\n",
    "predforest = modelforest.predict(A_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e390559",
   "metadata": {},
   "source": [
    "\n",
    "## Step 6: Confusion Matrices for Each Model\n",
    "\n",
    "- Here, I compared the predictions of each of the three models with confusion matrices.\n",
    "- A confusion matrix helps me to know the correct and incorrect classifications made by each model.\n",
    "- Each matrix is a 2x2 table that shows:\n",
    "  - True positives correctly predicted 1s\n",
    "  - True negatives correctly predicted 0s\n",
    "  - False positives incorrectly predicted 1s\n",
    "- Mislabeled 0s false negatives\n",
    "- I calculated the outcome by utilizing the confusion_matrix function in sklearn.\n",
    "- Comparing the matrices, I can simply look at which models are more accurate and where they are getting them wrong.\n",
    "- This step is worth it because it tells me more than accuracy alone — it tells me which types of errors each model is making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8c98339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Confusion Matrix:\n",
      " [[1239  112]\n",
      " [  64   85]]\n",
      "Decision Tree Confusion Matrix:\n",
      " [[1336   15]\n",
      " [  16  133]]\n",
      "Random Forest Confusion Matrix:\n",
      " [[1348    3]\n",
      " [  23  126]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Confusion Matrix:\\n\", confusion_matrix(B_val, prednb))\n",
    "print(\"Decision Tree Confusion Matrix:\\n\", confusion_matrix(B_val, preddt))\n",
    "print(\"Random Forest Confusion Matrix:\\n\", confusion_matrix(B_val, predforest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f813eb",
   "metadata": {},
   "source": [
    "\n",
    "## Step 7: Create DataFrame of Predictions\n",
    "\n",
    "I have created the DataFrame that contains:\n",
    "- The actual loan outcome\n",
    "- The predicted outcomes from each of the three models\n",
    "\n",
    "This helps organize predictions for later ensemble analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee31f02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Naive_Bayes_Pred</th>\n",
       "      <th>Decision_Tree_Pred</th>\n",
       "      <th>Random_Forest_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Naive_Bayes_Pred  Decision_Tree_Pred  Random_Forest_Pred\n",
       "0        0                 0                   0                   0\n",
       "1        0                 0                   0                   0\n",
       "2        0                 0                   0                   0\n",
       "3        0                 0                   0                   0\n",
       "4        0                 0                   0                   0\n",
       "..     ...               ...                 ...                 ...\n",
       "95       0                 0                   0                   0\n",
       "96       0                 0                   0                   0\n",
       "97       0                 0                   0                   0\n",
       "98       0                 0                   1                   0\n",
       "99       0                 0                   0                   0\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome = pd.DataFrame({\n",
    "    'Actual': B_val.values,\n",
    "    'Naive_Bayes_Pred': prednb,\n",
    "    'Decision_Tree_Pred': preddt,\n",
    "    'Random_Forest_Pred': predforest\n",
    "})\n",
    "outcome.head(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6717c5",
   "metadata": {},
   "source": [
    "\n",
    "## Step 8: Create Ensemble Predictions\n",
    "\n",
    "- Here, I converted the ensemble predictions of all three models into two ensemble outputs.\n",
    "- The first one I performed was Majority Vote, where I used the most common prediction of Naive Bayes, Decision Tree, and Random Forest for every observation.\n",
    "- The second one is Average Probability, where I calculated the average of the predicted probabilities of all three models.\n",
    "- I then established a cutoff of 0.5: if the mean probability was 0.5 or greater, I predicted 1; otherwise, I predicted 0.\n",
    "- Then, after generating both the ensemble columns, I printed out the first 100 predictions to observe how the ensemble methods compared to the actual values.\n",
    "- This enables me to view the agreement or disagreement visually among the models and have an idea of how the ensemble methods will perform on the validation set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9285d9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of Ensemble Predictions:\n",
      "    Actual  Majority_Vote  Average_Probability_Pred\n",
      "0        0              0                         0\n",
      "1        0              0                         0\n",
      "2        0              0                         0\n",
      "3        0              0                         0\n",
      "4        0              0                         0\n",
      "..     ...            ...                       ...\n",
      "95       0              0                         0\n",
      "96       0              0                         0\n",
      "97       0              0                         0\n",
      "98       0              0                         0\n",
      "99       0              0                         0\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "outcome['Majority_Vote'] = outcome[['Naive_Bayes_Pred', 'Decision_Tree_Pred', 'Random_Forest_Pred']].mode(axis=1)[0]\n",
    "probapilitynb = modelnb.predict_proba(A_val)[:, 1]\n",
    "probapilitydt = modeltree.predict_proba(A_val)[:, 1]\n",
    "probapilityrf = modelforest.predict_proba(A_val)[:, 1]\n",
    "avg_probs = (probapilitynb + probapilitydt + probapilityrf) / 3\n",
    "outcome['Average_Probability_Pred'] = np.where(avg_probs >= 0.5, 1, 0)\n",
    "print(\"Sample of Ensemble Predictions:\")\n",
    "print(outcome[['Actual', 'Majority_Vote', 'Average_Probability_Pred']].head(100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cbcb9",
   "metadata": {},
   "source": [
    "\n",
    "## Step 9: Confusion Matrices for Ensemble Methods\n",
    "\n",
    "Confusion matrices are generated for the Majority Vote and Average Probability ensemble methods. \n",
    "This helps evaluate how well the ensemble strategies perform compared to individual models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "937e1ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Confusion Matrix:\n",
      " [[1346    5]\n",
      " [  23  126]]\n",
      "Average Probability Confusion Matrix:\n",
      " [[1346    5]\n",
      " [  23  126]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Majority Vote Confusion Matrix:\\n\", confusion_matrix(B_val, outcome['Majority_Vote']))\n",
    "print(\"Average Probability Confusion Matrix:\\n\", confusion_matrix(B_val, outcome['Average_Probability_Pred']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22bc427",
   "metadata": {},
   "source": [
    "\n",
    "## Step 10: Compare Error Rates\n",
    "\n",
    "- I have calculated each model's error rate according to the following formula: Error Rate = 1 - Accuracy.\n",
    "- It says how often every model is making an incorrect prediction in the validation set.\n",
    "- Here I am comparing a total of five models:\n",
    "  - Naive Bayes\n",
    "  - Decision Tree\n",
    "  - Random Forest\n",
    "  - Ensemble method via Majority Vote\n",
    "  - Ensemble method via Average Probability\n",
    "- Here I have done a contrast each model's prediction with actual validation set outputs.\n",
    "- compute accuracy via the accuracy_score function in sklearn and determine the error rate by taking 1 minus that.\n",
    "- From this contrast, we can observe which model has the best minimization of error.\n",
    "- It also allows us to check whether minimization of error by ensemble methods with lots of models outcome in improved performance compared to individual models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c9987d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error Rates:\n",
      "Naive Bayes Error Rate: 0.1173\n",
      "Decision Tree Error Rate: 0.0207\n",
      "Random Forest Error Rate: 0.0173\n",
      "Majority Vote Error Rate: 0.0187\n",
      "Average Probability Error Rate: 0.0187\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nError Rates:\")\n",
    "print(f\"Naive Bayes Error Rate: {1 - accuracy_score(B_val, prednb):.4f}\")\n",
    "print(f\"Decision Tree Error Rate: {1 - accuracy_score(B_val, preddt):.4f}\")\n",
    "print(f\"Random Forest Error Rate: {1 - accuracy_score(B_val, predforest):.4f}\")\n",
    "print(f\"Majority Vote Error Rate: {1 - accuracy_score(B_val, outcome['Majority_Vote']):.4f}\")\n",
    "print(f\"Average Probability Error Rate: {1 - accuracy_score(B_val, outcome['Average_Probability_Pred']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2cb452",
   "metadata": {},
   "source": [
    "\n",
    "# Conclusion\n",
    "\n",
    "- In this project, three classification models were developed to predict loan acceptance: Naive Bayes, Decision Tree, and Random Forest.  \n",
    "- The dataset was carefully preprocessed, infinite values handled, and categorical variables were encoded.  \n",
    "- The models were trained and evaluated using a 70-30 train-validation split.  \n",
    "- Two ensemble strategies (Majority Voting and Average Probability) were also implemented to combine model predictions.\n",
    "- Confusion matrices and error rates were used to assess model performance.  \n",
    "- Through comparison, it is evident that ensemble methods generally improve the predictive accuracy compared to individual models.\n",
    "- Thus, the combination of simple preprocessing, basic classifiers, and ensemble techniques provided a solid framework for predicting loan acceptance outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efaa3de",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
